"""
s4_test_chunking.py
ê° ê¸°ê´€ë³„ processed.json íŒŒì¼ì„ ì²­í‚¹í•˜ì—¬ ì €ì¥

ì‚¬ìš©ë²•:
    python s4_test_chunking.py
"""

import sys
from pathlib import Path
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
src_path = project_root / "src"
sys.path.insert(0, str(src_path))

# src í´ë”ì˜ ëª¨ë“ˆ ì„í¬íŠ¸
from s4_chunking_strategy import ChunkingStrategy


def chunk_single_institution(institution: str):
    """
    ë‹¨ì¼ ê¸°ê´€ì˜ processed.jsonì„ ì²­í‚¹
    
    Args:
        institution: ê¸°ê´€ ì½”ë“œ (hd, kb, khi)
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“„ {institution.upper()} ì²­í‚¹ ì‹œì‘")
    print(f"{'='*80}\n")
    
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ
    input_file = project_root / "data" / "processed" / institution / f"{institution}_report_processed.json"
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not input_file.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        return None
    
    # ì²­í‚¹ ì „ëµ ì´ˆê¸°í™”
    chunker = ChunkingStrategy(
        chunk_size=800,
        overlap=100,
        model="gpt-4"
    )
    
    # JSON íŒŒì¼ ë¡œë“œ ë° ì²­í‚¹
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    institution_code = data.get("institution", institution)
    
    print(f"âœ“ JSON ë¡œë“œ ì™„ë£Œ: {input_file}")
    print(f"âœ“ ê¸°ê´€: {institution_code.upper()}")
    
    # í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    texts = data.get("texts", [])
    print(f"  - í…ìŠ¤íŠ¸: {len(texts)}ê°œ í˜ì´ì§€")
    
    # í‘œ ìˆ˜ì§‘
    tables = data.get("tables", [])
    print(f"  - í‘œ: {len(tables)}ê°œ")
    
    # ì´ë¯¸ì§€ ìˆ˜ì§‘
    images = data.get("images", [])
    print(f"  - ì´ë¯¸ì§€: {len(images)}ê°œ")
    
    # 1. í…ìŠ¤íŠ¸ ì²­í‚¹
    print(f"\n1ï¸âƒ£ í…ìŠ¤íŠ¸ ì²­í‚¹ ì¤‘...")
    text_blocks = []
    for text_data in texts:
        # ê° í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ë¸”ë¡ìœ¼ë¡œ ë³€í™˜
        text_blocks.append({
            "text": text_data.get("text", ""),
            "page_num": text_data.get("page_num", 0)
        })
    
    text_chunks = chunker.chunk_pages(text_blocks, institution_code)
    print(f"  âœ“ {len(text_chunks)}ê°œ í…ìŠ¤íŠ¸ ì²­í¬ ìƒì„±")
    
    # 2. í‘œ ì²­í‚¹
    print(f"\n2ï¸âƒ£ í‘œ ì²­í‚¹ ì¤‘...")
    table_chunks = []
    for table_data in tables:
        table_chunk = chunker.make_table_to_chunk(table_data)
        table_chunks.append(table_chunk)
    print(f"  âœ“ {len(table_chunks)}ê°œ í‘œ ì²­í¬ ìƒì„±")
    
    # 3. ì´ë¯¸ì§€ ì²­í‚¹
    print(f"\n3ï¸âƒ£ ì´ë¯¸ì§€ ì²­í‚¹ ì¤‘...")
    image_chunks = []
    for image_data in images:
        image_chunk = chunker.make_image_to_chunk(image_data)
        image_chunks.append(image_chunk)
    print(f"  âœ“ {len(image_chunks)}ê°œ ì´ë¯¸ì§€ ì²­í¬ ìƒì„±")
    
    # 4. ëª¨ë“  ì²­í¬ ê²°í•©
    all_chunks = text_chunks + table_chunks + image_chunks
    
    # 5. ì˜¤ë²„ë© ì ìš©
    print(f"\n4ï¸âƒ£ ì˜¤ë²„ë© ì ìš© ì¤‘...")
    final_chunks = chunker.apply_overlap(all_chunks)
    print(f"  âœ“ ìµœì¢… {len(final_chunks)}ê°œ ì²­í¬ ìƒì„±")
    
    # 6. ê²°ê³¼ ì €ì¥
    output_dir = project_root / "data" / "processed" / institution
    output_file = output_dir / f"{institution}_chunks.json"
    
    chunker.save_chunks(final_chunks, str(output_file))
    
    print(f"\n{'='*80}")
    print(f"âœ… {institution.upper()} ì²­í‚¹ ì™„ë£Œ!")
    print(f"{'='*80}\n")
    
    return final_chunks


def main():
    """
    ë©”ì¸ í•¨ìˆ˜: ëª¨ë“  ê¸°ê´€ ì²­í‚¹
    """
    institutions = ["hd", "kb", "khi"]
    
    print("\n" + "="*80)
    print("ğŸš€ ì „ì²´ ê¸°ê´€ ì²­í‚¹ ì‹œì‘")
    print("="*80)
    
    results = {}
    
    for institution in institutions:
        try:
            chunks = chunk_single_institution(institution)
            if chunks:
                results[institution] = len(chunks)
        except Exception as e:
            print(f"\nâŒ {institution.upper()} ì²­í‚¹ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ì „ì²´ ìš”ì•½
    print("\n" + "="*80)
    print("âœ… ì „ì²´ ì²­í‚¹ ì™„ë£Œ!")
    print("="*80)
    
    for institution, count in results.items():
        print(f"  - {institution.upper()}: {count}ê°œ ì²­í¬")
        output_file = project_root / "data" / "processed" / institution / f"{institution}_chunks.json"
        print(f"    â†’ {output_file}")
    
    print("="*80 + "\n")


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ 1: ì „ì²´ ì²­í‚¹
    main()
    
    # ì‚¬ìš© ì˜ˆì‹œ 2: íŠ¹ì • ê¸°ê´€ë§Œ ì²­í‚¹
    # chunk_single_institution("hd")