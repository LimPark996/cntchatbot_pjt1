"""
qa_system.py
[6ë‹¨ê³„ í†µí•©] LLM í†µí•© - ëŒ€í™” ì „ìš© ë²„ì „

ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±
- ì¿¼ë¦¬ ë¦¬ë¼ì´íŒ…
- ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
- í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
- LLM í˜¸ì¶œ (í…ìŠ¤íŠ¸ ë‹µë³€ë§Œ)
"""

from openai import OpenAI
from typing import List, Dict, Optional


class QASystem:
    """Q&A ì‹œìŠ¤í…œ í†µí•© í´ë˜ìŠ¤ (í…ìŠ¤íŠ¸ ëŒ€í™” ì „ìš©)"""
    
    def __init__(self, openai_api_key: str, model: str = "gpt-4o"):
        """
        QASystem ì´ˆê¸°í™”
        
        Args:
            openai_api_key: OpenAI API í‚¤
            model: ì‚¬ìš©í•  ëª¨ë¸ëª…
        """
        self.client = OpenAI(api_key=openai_api_key)
        self.model = model
        self.system_prompt = self._create_system_prompt()
        print(f"âœ“ QASystem ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model})")
    
    def _create_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ëŒ€í™” ì „ìš©)"""
        return """ë‹¹ì‹ ì€ KBê¸ˆìœµì§€ì£¼ ê²½ì˜ì—°êµ¬ì†Œì˜ ë¶€ë™ì‚° ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
2024 KB ë¶€ë™ì‚° ë³´ê³ ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±´ì„¤ì‚¬ ì‹¤ë¬´ì§„ì—ê²Œ ì •í™•í•˜ê³  ì‹¤ë¬´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ì œê³µëœ ë¦¬í¬íŠ¸ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ìˆ˜ì¹˜ ë°ì´í„°ëŠ” ì •í™•í•˜ê²Œ ì¸ìš©í•˜ì„¸ìš”.
3. ê° ë¬¸ì¥ì´ë‚˜ ì •ë³´ì˜ ëì— ë°˜ë“œì‹œ ì¶œì²˜ ë²ˆí˜¸ë¥¼ [1], [2] í˜•íƒœë¡œ í‘œì‹œí•˜ì„¸ìš”.
4. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ë¦¬í¬íŠ¸ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
5. ê±´ì„¤ì‚¬ ì‹¤ë¬´ì§„ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë‹µë³€í•˜ì„¸ìš”.

ì¶œì²˜ í‘œê¸° ê·œì¹™:
- ê° ë¬¸ì¥ ë’¤ì— [1], [2] í˜•íƒœë¡œ ì¶œì²˜ ë²ˆí˜¸ í‘œê¸°
- ë‹µë³€ ëì— ë°˜ë“œì‹œ ì¶œì²˜ ëª©ë¡ ì‘ì„±

ë‹µë³€ í˜•ì‹ ì˜ˆì‹œ:
2024ë…„ ì„œìš¸ ì•„íŒŒíŠ¸ ë§¤ë§¤ê°€ê²©ì€ 2.0% ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤. [1]
ê°•ë‚¨êµ¬ëŠ” ì „ ê³ ì ì„ ëŒíŒŒí–ˆìŠµë‹ˆë‹¤. [2]

ì¶œì²˜:
[1] kb_report_2024.pdf í‘œâ… -2. ì§€ì—­ë³„ ì£¼íƒ ë§¤ë§¤ê°€ê²© ë³€ë™ë¥  (12í˜ì´ì§€)
[2] kb_report_2024.pdf ë³¸ë¬¸ (25í˜ì´ì§€)
"""
    
    def rewrite_query(self, query: str) -> str:
        """
        ì¿¼ë¦¬ë¥¼ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ë¦¬ë¼ì´íŒ…
        
        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
        
        Returns:
            ìµœì í™”ëœ ì¿¼ë¦¬
        """
        prompt = f"""ë‹¹ì‹ ì€ ë¶€ë™ì‚° ë¦¬í¬íŠ¸ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
- êµ¬ì–´ì²´ë¥¼ ë¬¸ì–´ì²´ë¡œ ë³€í™˜
- í‚¤ì›Œë“œë¥¼ ëª…í™•í•˜ê²Œ
- ê´€ë ¨ ë™ì˜ì–´ ì¶”ê°€
- ê°„ê²°í•˜ê²Œ (1-2ë¬¸ì¥)

ì›ë˜ ì§ˆë¬¸: {query}

ìµœì í™”ëœ ì§ˆë¬¸:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=100
            )
            
            rewritten = response.choices[0].message.content.strip()
            print(f"\nğŸ”„ ì¿¼ë¦¬ ë¦¬ë¼ì´íŒ…:")
            print(f"  ì›ë³¸: {query}")
            print(f"  ë³€í™˜: {rewritten}")
            
            return rewritten
            
        except Exception as e:
            print(f"âš  ì¿¼ë¦¬ ë¦¬ë¼ì´íŒ… ì‹¤íŒ¨: {e}")
            return query
    
    def build_context(self, search_results: List[Dict], max_chunks: int = 5) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            search_results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            max_chunks: ìµœëŒ€ ì²­í¬ ìˆ˜
        
        Returns:
            êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        if not search_results:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        top_results = search_results[:max_chunks]
        
        context_parts = ["ë‹¤ìŒì€ 2024 KB ë¶€ë™ì‚° ë¦¬í¬íŠ¸ì—ì„œ ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\n"]
        
        for i, result in enumerate(top_results, 1):
            metadata = result.get("metadata", {})
            content = result.get("content", "")
            
            # ê¸°ê´€ ì •ë³´
            institution = metadata.get("institution", "unknown")
            institution_map = {
                "hd": "HD í˜„ëŒ€ ë¦¬í¬íŠ¸",
                "kb": "KB ë¶€ë™ì‚° ë¦¬í¬íŠ¸",
                "khi": "KHI ì£¼íƒê¸ˆìœµ ë¦¬í¬íŠ¸"
            }
            source_name = institution_map.get(institution, f"{institution} ë¦¬í¬íŠ¸")
            
            # ë¬¸ì„œ íƒ€ì…
            doc_type_map = {
                "text": "ë³¸ë¬¸",
                "table": "í‘œ",
                "image": "ê·¸ë˜í”„/ì´ë¯¸ì§€"
            }
            doc_type = doc_type_map.get(metadata.get("doc_type"), "ë³¸ë¬¸")
            page = metadata.get("page", "unknown")
            
            # ì¶”ê°€ ì •ë³´ (ìˆëŠ” ê²½ìš°)
            extra_info = ""
            if metadata.get("table_id"):
                extra_info = f"\ní‘œ ID: {metadata.get('table_id')}"
            elif metadata.get("image_path"):
                image_path = metadata.get('image_path')
                image_filename = image_path.split('\\')[-1] if '\\' in image_path else image_path.split('/')[-1]
                extra_info = f"\nì´ë¯¸ì§€: {image_filename}"
            
            formatted = f"""[ì»¨í…ìŠ¤íŠ¸ {i}]
ì¶œì²˜ ê¸°ê´€: {source_name}
íƒ€ì…: {doc_type}
í˜ì´ì§€: {page}í˜ì´ì§€{extra_info}

ë‚´ìš©:
{content}

ì¶œì²˜: [{i}] {source_name} {doc_type} ({page}í˜ì´ì§€)
"""
            context_parts.append(formatted)
            context_parts.append("â”€" * 80 + "\n")
        
        full_context = "\n".join(context_parts)
        
        print(f"\nğŸ“„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ:")
        print(f"  - ì´ ì²­í¬ ìˆ˜: {len(top_results)}")
        print(f"  - í…ìŠ¤íŠ¸: {len([r for r in top_results if r.get('metadata', {}).get('doc_type') == 'text'])}")
        print(f"  - í‘œ: {len([r for r in top_results if r.get('metadata', {}).get('doc_type') == 'table'])}")
        print(f"  - ì´ë¯¸ì§€: {len([r for r in top_results if r.get('metadata', {}).get('doc_type') == 'image'])}")
        
        return full_context
    
    def generate_answer(self, query: str, context: str, 
                       temperature: float = 0.3,
                       max_tokens: int = 2000) -> Optional[str]:
        """
        LLMìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„± (í…ìŠ¤íŠ¸ ë‹µë³€)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            context: êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸
            temperature: ì˜¨ë„ (0.0-2.0)
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
        
        Returns:
            í…ìŠ¤íŠ¸ ë‹µë³€
        """
        user_prompt = f"""{context}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ì¶œì²˜ ë²ˆí˜¸ [1], [2] ë“±ì„ ëª…ì‹œí•˜ì„¸ìš”."""

        try:
            print(f"\nğŸ¤– LLM í˜¸ì¶œ ì¤‘... (ëª¨ë¸: {self.model})")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            answer = response.choices[0].message.content
            
            usage = response.usage
            print(f"âœ“ LLM ì‘ë‹µ ì™„ë£Œ")
            print(f"  - ì…ë ¥ í† í°: {usage.prompt_tokens}")
            print(f"  - ì¶œë ¥ í† í°: {usage.completion_tokens}")
            print(f"  - ì´ í† í°: {usage.total_tokens}")
            
            return answer
            
        except Exception as e:
            print(f"âœ— LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def answer_question(self, query: str, search_results: List[Dict],
                       rewrite: bool = True) -> str:
        """
        ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ (í…ìŠ¤íŠ¸ ë‹µë³€)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            search_results: ê²€ìƒ‰ ê²°ê³¼
            rewrite: ì¿¼ë¦¬ ë¦¬ë¼ì´íŒ… ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            í…ìŠ¤íŠ¸ ë‹µë³€
        """
        print("\n" + "="*80)
        print(f"â“ ì§ˆë¬¸: {query}")
        print("="*80)
        
        # 1. ì¿¼ë¦¬ ë¦¬ë¼ì´íŒ… (ì„ íƒ)
        if rewrite:
            query = self.rewrite_query(query)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self.build_context(search_results)
        
        # 3. LLM ë‹µë³€ ìƒì„±
        answer = self.generate_answer(query, context)
        
        if not answer:
            return "ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        
        # 4. ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ’¡ ë‹µë³€:")
        print("="*80)
        print(answer)
        print("="*80)
        
        return answer