"""
test_full_pipeline.py
ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸: ê²€ìƒ‰ ì—”ì§„ + QA ì‹œìŠ¤í…œ

ì‹¤ì œ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
"""

import os
import json
from dotenv import load_dotenv
from src.s5_embedding_manager import EmbeddingManager
from src.s6_search_engine import SearchEngine
from src.s7_qa_system_light import QASystem

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


def load_vector_store(institution: str = "kb"):
    """
    ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    
    Args:
        institution: ê¸°ê´€ëª… (hd, kb, khi)
    
    Returns:
        (faiss_index, metadata, chunks)
    """
    print(f"\nğŸ“‚ {institution.upper()} ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...")
    
    # ê²½ë¡œ ì„¤ì •
    vector_store_dir = f"data/vector_store/{institution}"
    processed_dir = f"data/processed/{institution}"
    
    index_path = os.path.join(vector_store_dir, "faiss_index.bin")
    metadata_path = os.path.join(vector_store_dir, "metadata.json")
    chunks_path = os.path.join(processed_dir, f"{institution}_chunks.json")
    
    # EmbeddingManager ì´ˆê¸°í™”
    embedding_manager = EmbeddingManager(
        openai_api_key=OPENAI_API_KEY,
        model="text-embedding-3-large"
    )
    
    # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
    faiss_index = embedding_manager.load_index(index_path)
    if not faiss_index:
        raise FileNotFoundError(f"FAISS ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {index_path}")
    
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    metadata = embedding_manager.load_metadata(metadata_path)
    if not metadata:
        raise FileNotFoundError(f"ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_path}")
    
    # ì²­í¬ ë¡œë“œ (BM25ìš©)
    with open(chunks_path, 'r', encoding='utf-8') as f:
        chunks = json.load(f)
    print(f"âœ“ ì²­í¬ ë¡œë“œ: {len(chunks)}ê°œ")
    
    return faiss_index, metadata, chunks, embedding_manager


def test_single_institution(institution: str = "kb"):
    """ë‹¨ì¼ ê¸°ê´€ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print(f"ğŸš€ {institution.upper()} ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # 1. ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    faiss_index, metadata, chunks, embedding_manager = load_vector_store(institution)
    
    # 2. ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    print("\nğŸ” ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    search_engine = SearchEngine(
        faiss_index=faiss_index,
        metadata=metadata,
        chunks=chunks,
        embedding_manager=embedding_manager
    )
    
    # 3. QA ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("\nğŸ¤– QA ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    qa_system = QASystem(
        openai_api_key=OPENAI_API_KEY,
        model="gpt-4o"
    )
    
    # 4. ì§ˆë¬¸ ë‹µë³€ í…ŒìŠ¤íŠ¸
    query = "2024ë…„ ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ë³€ë™ë¥ ì€?"
    
    print("\n" + "="*80)
    print(f"â“ ì§ˆë¬¸: {query}")
    print("="*80)
    
    # ê²€ìƒ‰ ìˆ˜í–‰
    print("\nğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
    search_results = search_engine.hybrid_search(query, top_k=5)
    
    print(f"âœ“ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
    for i, result in enumerate(search_results, 1):
        print(f"  {i}. [{result['metadata'].get('institution', 'unknown')}] "
              f"RRF Score: {result.get('rrf_score', 0):.4f}")
    
    # ë‹µë³€ ìƒì„±
    answer = qa_system.answer_question(
        query=query,
        search_results=search_results,
        rewrite=True
    )
    
    print("\nâœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return answer


def test_multi_institution():
    """ì—¬ëŸ¬ ê¸°ê´€ í†µí•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("ğŸš€ ë‹¤ì¤‘ ê¸°ê´€ í†µí•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    institutions = ["hd", "kb", "khi"]
    all_results = []
    
    # QA ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    qa_system = QASystem(
        openai_api_key=OPENAI_API_KEY,
        model="gpt-4o"
    )
    
    query = "2024ë…„ ë¶€ë™ì‚° ì‹œì¥ ì „ë§ì€?"
    
    # ê° ê¸°ê´€ë³„ë¡œ ê²€ìƒ‰
    for institution in institutions:
        try:
            print(f"\nğŸ“‚ {institution.upper()} ê²€ìƒ‰ ì¤‘...")
            faiss_index, metadata, chunks, embedding_manager = load_vector_store(institution)
            
            search_engine = SearchEngine(
                faiss_index=faiss_index,
                metadata=metadata,
                chunks=chunks,
                embedding_manager=embedding_manager
            )
            
            results = search_engine.hybrid_search(query, top_k=3)
            all_results.extend(results)
            print(f"âœ“ {institution.upper()}: {len(results)}ê°œ ê²°ê³¼")
            
        except Exception as e:
            print(f"âš  {institution.upper()} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            continue
    
    # í†µí•© ê²°ê³¼ë¡œ ë‹µë³€ ìƒì„±
    if all_results:
        print(f"\nğŸ“Š ì´ {len(all_results)}ê°œ ê²°ê³¼ë¡œ ë‹µë³€ ìƒì„±")
        answer = qa_system.answer_question(
            query=query,
            search_results=all_results,
            rewrite=True
        )
        print("\nâœ… ë‹¤ì¤‘ ê¸°ê´€ í†µí•© ê²€ìƒ‰ ì™„ë£Œ!")
        return answer
    else:
        print("âš  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None


def test_search_types():
    """ê²€ìƒ‰ íƒ€ì…ë³„ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("ğŸ” ê²€ìƒ‰ íƒ€ì…ë³„ ì„±ëŠ¥ ë¹„êµ")
    print("="*80)
    
    # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
    faiss_index, metadata, chunks, embedding_manager = load_vector_store("kb")
    
    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    search_engine = SearchEngine(
        faiss_index=faiss_index,
        metadata=metadata,
        chunks=chunks,
        embedding_manager=embedding_manager
    )
    
    # QA ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    qa_system = QASystem(
        openai_api_key=OPENAI_API_KEY,
        model="gpt-4o"
    )
    
    query = "ê°•ë‚¨êµ¬ ì•„íŒŒíŠ¸ ê°€ê²©"
    
    # 1. ë²¡í„° ê²€ìƒ‰ë§Œ
    print("\n1ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜)")
    vector_results = search_engine.vector_search(query, top_k=5)
    print(f"ê²°ê³¼: {len(vector_results)}ê°œ")
    
    # 2. í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ
    print("\n2ï¸âƒ£ í‚¤ì›Œë“œ ê²€ìƒ‰ (BM25)")
    keyword_results = search_engine.keyword_search(query, top_k=5)
    print(f"ê²°ê³¼: {len(keyword_results)}ê°œ")
    
    # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    print("\n3ï¸âƒ£ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (RRF)")
    hybrid_results = search_engine.hybrid_search(query, top_k=5)
    print(f"ê²°ê³¼: {len(hybrid_results)}ê°œ")
    
    # í•˜ì´ë¸Œë¦¬ë“œë¡œ ë‹µë³€ ìƒì„±
    print("\nğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ë¡œ ë‹µë³€ ìƒì„±:")
    answer = qa_system.answer_question(
        query=query,
        search_results=hybrid_results,
        rewrite=False
    )
    
    print("\nâœ… ê²€ìƒ‰ íƒ€ì… ë¹„êµ ì™„ë£Œ!")
    return answer


def interactive_mode(institution: str = "kb"):
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("\n" + "="*80)
    print(f"ğŸ’¬ ëŒ€í™”í˜• ëª¨ë“œ ({institution.upper()} ë¦¬í¬íŠ¸)")
    print("="*80)
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    # ì´ˆê¸°í™”
    faiss_index, metadata, chunks, embedding_manager = load_vector_store(institution)
    
    search_engine = SearchEngine(
        faiss_index=faiss_index,
        metadata=metadata,
        chunks=chunks,
        embedding_manager=embedding_manager
    )
    
    qa_system = QASystem(
        openai_api_key=OPENAI_API_KEY,
        model="gpt-4o"
    )
    
    # ëŒ€í™” ë£¨í”„
    while True:
        try:
            query = input("\nì§ˆë¬¸: ").strip()
            
            if query.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                print("\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not query:
                continue
            
            # ê²€ìƒ‰ + ë‹µë³€
            search_results = search_engine.hybrid_search(query, top_k=5)
            answer = qa_system.answer_question(
                query=query,
                search_results=search_results,
                rewrite=True
            )
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâš  ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    print("\n" + "ğŸ  " + "="*76)
    print("ë¶€ë™ì‚° ë¦¬í¬íŠ¸ QA ì‹œìŠ¤í…œ - ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # API í‚¤ í™•ì¸
    if not OPENAI_API_KEY:
        print("âš ï¸  ê²½ê³ : .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”!")
        exit(1)
    
    print(f"âœ“ API í‚¤ ë¡œë“œ ì™„ë£Œ")
    
    # í…ŒìŠ¤íŠ¸ ì„ íƒ
    print("\ní…ŒìŠ¤íŠ¸ ì˜µì…˜:")
    print("1. ë‹¨ì¼ ê¸°ê´€ í…ŒìŠ¤íŠ¸ (KB)")
    print("2. ë‹¨ì¼ ê¸°ê´€ í…ŒìŠ¤íŠ¸ (HD)")
    print("3. ë‹¨ì¼ ê¸°ê´€ í…ŒìŠ¤íŠ¸ (KHI)")
    print("4. ë‹¤ì¤‘ ê¸°ê´€ í†µí•© ê²€ìƒ‰")
    print("5. ê²€ìƒ‰ íƒ€ì… ë¹„êµ")
    print("6. ëŒ€í™”í˜• ëª¨ë“œ (KB)")
    print("7. ëŒ€í™”í˜• ëª¨ë“œ (HD)")
    print("8. ëŒ€í™”í˜• ëª¨ë“œ (KHI)")
    
    choice = input("\nì„ íƒ (1-8): ").strip()
    
    try:
        if choice == "1":
            test_single_institution("kb")
        elif choice == "2":
            test_single_institution("hd")
        elif choice == "3":
            test_single_institution("khi")
        elif choice == "4":
            test_multi_institution()
        elif choice == "5":
            test_search_types()
        elif choice == "6":
            interactive_mode("kb")
        elif choice == "7":
            interactive_mode("hd")
        elif choice == "8":
            interactive_mode("khi")
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. KB í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            test_single_institution("kb")
    except FileNotFoundError as e:
        print(f"\nâŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("\ní•„ìš”í•œ íŒŒì¼:")
        print("  - data/vector_store/{institution}/faiss_index.bin")
        print("  - data/vector_store/{institution}/metadata.json")
        print("  - data/processed/{institution}/{institution}_chunks.json")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*80)
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)