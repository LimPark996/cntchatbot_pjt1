import streamlit as st
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¶€ë™ì‚° ë¦¬í¬íŠ¸ Q&A AI",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    /* ê¸°ë³¸ ë°°ê²½ìƒ‰ (ì „ì²´ ì•±) */
    .stApp {
        background-color: white; /* í°ìƒ‰ ë°°ê²½ */
        color: #000000; /* ì•± ì „ì²´ ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ì„¤ì • */
    }
    
    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ (ì§„í•œ ì²­ë¡ìƒ‰) */
    [data-testid="stSidebar"] {
        background-color: #0e7490; /* ì§„í•œ ì²­ë¡ìƒ‰ */
    }
    
    /* ì‚¬ì´ë“œë°” ë‚´ë¶€ ë²„íŠ¼ ìŠ¤íƒ€ì¼ (ìì£¼ ë¬»ëŠ” ì§ˆë¬¸/ìµœê·¼ ì§ˆë¬¸ ë²„íŠ¼) */
    [data-testid="stSidebar"] .stButton button {
        background-color: #164e63; /* ë²„íŠ¼ ë°°ê²½ìƒ‰: ë” ì§„í•œ ì²­ë¡ìƒ‰ */
        color: white; /* ì‚¬ì´ë“œë°” ë²„íŠ¼ í…ìŠ¤íŠ¸ëŠ” í°ìƒ‰ ìœ ì§€ */
        border: none;
        width: 100%;
        text-align: left;
        padding: 12px;
        margin: 5px 0;
        border-radius: 5px;
        box-shadow: none; 
    }
    
    /* ë²„íŠ¼ í˜¸ë²„ ì‹œ ìƒ‰ìƒ */
    [data-testid="stSidebar"] .stButton button:hover {
        background-color: #0e7490; 
    }
    
    /* ì±—ë´‡ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .bot-message {
        background-color: #e0f7fa; /* ì˜…ì€ í•˜ëŠ˜ìƒ‰ ê³„ì—´ */
        color: #000000 !important; /* ì±—ë´‡ ë©”ì‹œì§€ í…ìŠ¤íŠ¸: ê²€ì€ìƒ‰ */
        padding: 15px;
        border-radius: 10px;
        margin: 10px 0;
        border-left: 5px solid #0e7490; 
    }
    
    /* ì‚¬ìš©ì ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .user-message {
        background-color: #f0f0f0; /* ì˜…ì€ íšŒìƒ‰ */
        color: #000000 !important; /* ì‚¬ìš©ì ë©”ì‹œì§€ í…ìŠ¤íŠ¸: ê²€ì€ìƒ‰ */
        padding: 15px;
        border-radius: 10px;
        margin: 10px 0;
        text-align: right;
    }
    
    /* ì°¸ê³ ìë£Œ ë°•ìŠ¤ */
    .reference-box {
        background-color: #fefce8; 
        color: #000000 !important; /* ì°¸ê³ ìë£Œ í…ìŠ¤íŠ¸: ê²€ì€ìƒ‰ */
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        border-left: 4px solid #eab308;
    }
    
    /* ì‚¬ì´ë“œë°” í—¤ë” ìŠ¤íƒ€ì¼ */
    .header-icon {
        display: flex;
        align-items: center;
        gap: 10px;
        color: white; /* ì‚¬ì´ë“œë°” í—¤ë”ëŠ” í°ìƒ‰ ìœ ì§€ */
        font-size: 1.5em;
        font-weight: bold;
        padding: 10px 15px; 
    }
    
    /* ì„¤ì • ìŠ¬ë¼ì´ë” ìº¡ì…˜ (ì‚¬ì´ë“œë°” ë‚´ë¶€) */
    [data-testid="stSidebar"] div.stCaption {
        color: #e0f7fa !important; 
    }
    
    /* ì¼ë°˜ í…ìŠ¤íŠ¸ (ì‚¬ì´ë“œë°” ë‚´ë¶€) */
    [data-testid="stSidebar"] h3, [data-testid="stSidebar"] label {
        color: white !important; /* ì‚¬ì´ë“œë°” í…ìŠ¤íŠ¸ëŠ” í°ìƒ‰ ìœ ì§€ */
    }

    /* ë©”ì¸ ì˜ì—­ ì œëª©/ë¶€ì œëª© */
    h1, h2, h3, h4, h5, h6 {
        color: #000000 !important; /* ëª¨ë“  ì œëª©ì€ ê²€ì€ìƒ‰ */
    }
    
    /* ì±„íŒ… ì…ë ¥ì°½ í…ìŠ¤íŠ¸ ë° ë°°ê²½ */
    [data-testid="stChatInput"] input,
    [data-testid="stChatInput"] textarea {
        color: #000000 !important; /* ì…ë ¥ í…ìŠ¤íŠ¸: ê²€ì€ìƒ‰ */
        background-color: white !important;
    }
    
    /* ì‹œê°í™” ë¯¸ë¦¬ë³´ê¸° ë‚´ë¶€ info ë°•ìŠ¤ */
    .stAlert.info {
        background-color: #f0f0f0; 
        border-left-color: #0e7490;
        color: #000000 !important; /* info ë°•ìŠ¤ í…ìŠ¤íŠ¸: ê²€ì€ìƒ‰ */
    }
    
    /* íƒ­ ë©”ë‰´ ìŠ¤íƒ€ì¼ */
    .stTabs [data-testid="stTab"] {
        color: #000000 !important; /* íƒ­ ê¸€ììƒ‰: ê²€ì€ìƒ‰ (ì¤‘ìš”) */
        background-color: transparent !important; /* íƒ­ ë°°ê²½ íˆ¬ëª… */
    }

    /* ì„ íƒëœ íƒ­ì˜ ë°‘ì¤„ ìƒ‰ìƒ (ë¹¨ê°„ìƒ‰) */
    .stTabs [data-testid="stTab"][aria-selected="true"] {
        border-bottom: 2px solid red !important; /* ì„ íƒëœ íƒ­ ë°‘ì¤„: ë¹¨ê°„ìƒ‰ (ì¤‘ìš”) */
        color: red !important; /* ì„ íƒëœ íƒ­ ê¸€ììƒ‰: ë¹¨ê°„ìƒ‰ */
    }

    /* ì„ íƒë˜ì§€ ì•Šì€ íƒ­ì˜ ë°‘ì¤„ (ë³´í†µ Streamlit ê¸°ë³¸ì€ íšŒìƒ‰) */
    .stTabs [data-testid="stTab"][aria-selected="false"] {
        border-bottom: 2px solid transparent !important; /* ì„ íƒë˜ì§€ ì•Šì€ íƒ­ ë°‘ì¤„ íˆ¬ëª… */
    }

    /* ê¸°íƒ€ ìº¡ì…˜/ì‘ì€ ê¸€ì”¨ (ë©”ì¸ ì˜ì—­) */
    .stCaption, .stMarkdown small, .stMarkdown p {
        color: #000000 !important; /* ë©”ì¸ ì˜ì—­ì˜ ì¼ë°˜ í…ìŠ¤íŠ¸/ìº¡ì…˜ ê²€ì€ìƒ‰ */
    }
    
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'current_section' not in st.session_state:
    st.session_state.current_section = "ì„œìš¸ ì•„íŒŒíŠ¸ ì£¼ê°„ ì‹œí™©"

if 'references' not in st.session_state:
    st.session_state.references = []

if 'qa_system' not in st.session_state:
    st.session_state.qa_system = None

if 'search_engine' not in st.session_state:
    st.session_state.search_engine = None

if 'user_questions' not in st.session_state:
    st.session_state.user_questions = []  # ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¸ ì§ˆë¬¸ íˆìŠ¤í† ë¦¬

# .envì—ì„œ OpenAI API í‚¤ ë¡œë“œ ë° QA ì‹œìŠ¤í…œ ìë™ ì´ˆê¸°í™”
if st.session_state.qa_system is None:
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        try:
            from src.s7_qa_system_light import QASystem
            st.session_state.qa_system = QASystem(openai_api_key=api_key, model="gpt-4o")
            print("âœ… QA ì‹œìŠ¤í…œì´ .envì˜ API í‚¤ë¡œ ìë™ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except ImportError:
            st.error("âš ï¸ s7_qa_system_light.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âŒ QA ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    else:
        st.warning("âš ï¸ .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
if st.session_state.search_engine is None:
    import json
    import faiss
    from pathlib import Path
    from src.s6_search_engine import SearchEngine
    
    try:
        # ê²½ë¡œ ì„¤ì •
        vector_store_path = Path("data/vector_store/kb")
        processed_path = Path("data/processed/kb")
        
        faiss_index_path = vector_store_path / "faiss_index.bin"
        metadata_path = vector_store_path / "metadata.json"
        chunks_path = processed_path / "kb_chunks.json"
        
        # íŒŒì¼ ë¡œë“œ
        faiss_index = faiss.read_index(str(faiss_index_path))
        
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        with open(chunks_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
        
        # EmbeddingManager ì´ˆê¸°í™” (ì¿¼ë¦¬ ì„ë² ë”©ìš©)
        from src.s5_embedding_manager import EmbeddingManager
        api_key = os.getenv("OPENAI_API_KEY")
        embedding_manager = EmbeddingManager(openai_api_key=api_key)
        
        # SearchEngine ì´ˆê¸°í™”
        st.session_state.search_engine = SearchEngine(
            faiss_index=faiss_index,
            metadata=metadata,
            chunks=chunks,
            embedding_manager=embedding_manager
        )
        print("âœ… Search Engineì´ ìë™ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"  - FAISS ì¸ë±ìŠ¤: {faiss_index.ntotal}ê°œ ë²¡í„°")
        print(f"  - ë©”íƒ€ë°ì´í„°: {len(metadata)}ê°œ")
        print(f"  - ì²­í¬: {len(chunks)}ê°œ")
        
    except FileNotFoundError as e:
        print(f"âš ï¸ ë²¡í„° DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.session_state.search_engine = None
    except Exception as e:
        print(f"âŒ Search Engine ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.session_state.search_engine = None
# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown('<div class="header-icon">ğŸ›ï¸ ë¶€ë™ì‚° ë¦¬í¬íŠ¸ Q&A AI</div>', unsafe_allow_html=True)
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
    st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    if st.session_state.qa_system:
        st.success("âœ… QA ì‹œìŠ¤í…œ ì—°ê²°ë¨")
    else:
        st.error("âŒ QA ì‹œìŠ¤í…œ ë¯¸ì—°ê²°")
        st.caption(".env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
    
    if st.session_state.search_engine:
        st.success("âœ… ë²¡í„° DB ì—°ê²°ë¨")
    else:
        st.warning("âš ï¸ ë²¡í„° DB ë¯¸ì—°ê²°")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¦¬ì…‹ ë²„íŠ¼
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        if st.session_state.qa_system:
            st.session_state.qa_system.clear_history()
        st.rerun()
    
    st.markdown("---")
    
    # ìµœê·¼ ë¬¼ì–´ë³¸ ì§ˆë¬¸ (ë™ì ìœ¼ë¡œ í‘œì‹œ)
    st.markdown("### ğŸ’¬ ìµœê·¼ ë¬¼ì–´ë³¸ ì§ˆë¬¸")
    
    # ìµœê·¼ 4ê°œì˜ ì‚¬ìš©ì ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
    recent_questions = st.session_state.user_questions[-4:][::-1]  # ìµœê·¼ 4ê°œ, ì—­ìˆœ
    
    if recent_questions:
        for idx, question in enumerate(recent_questions):
            # ì§ˆë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ ì¶•ì•½
            display_question = question if len(question) <= 30 else question[:27] + "..."
            if st.button(display_question, key=f"recent_q_{idx}", use_container_width=True):
                # í•´ë‹¹ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì…ë ¥ì°½ì— ì„¤ì •
                st.session_state.selected_question = question
    else:
        st.caption("ì•„ì§ ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    st.markdown("### âš™ï¸ ì„¤ì •")
    
    temperature = st.slider(
        "ê²€ìƒ‰ ë¯¼ê°ë„ (Temperature)",
        min_value=0.0,
        max_value=1.0,
        value=0.3,
        step=0.1,
        help="ë‚®ì„ìˆ˜ë¡ ì •í™•í•˜ê³  ì¼ê´€ëœ ë‹µë³€"
    )
    
    top_k = st.slider(
        "ì°¸ê³ í•  í˜ì´ì§€ ìˆ˜ (Top-k)",
        min_value=1,
        max_value=10,
        value=5,
        step=1,
        help="ê²€ìƒ‰í•  ë¬¸ì„œ ì²­í¬ ìˆ˜"
    )
    
    use_conversation = st.checkbox(
        "ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©",
        value=True,
        help="ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€ (í‹°í‚¤íƒ€ì¹´ ëŒ€í™”)"
    )

# RAG ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (qa_system.pyì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê¸°ëŠ¥ í™œìš©)
def generate_response(query: str, temperature: float, top_k: int, use_conversation: bool = True) -> tuple:
    """
    ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ ì§€ì›)
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        temperature: ìƒì„± ì˜¨ë„
        top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
        use_conversation: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        (ì‘ë‹µ í…ìŠ¤íŠ¸, ì°¸ê³  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸)
    """
    # QASystemì´ ì´ˆê¸°í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if st.session_state.qa_system is None:
        response = "âš ï¸ QA ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        return response, []
    
    if st.session_state.search_engine is None:
        response = "âš ï¸ ë²¡í„° DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ë²¡í„° DBë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
        return response, []
    
    try:
        # 1. ê²€ìƒ‰ ìˆ˜í–‰ (search_engine ì‚¬ìš©)
        search_results = st.session_state.search_engine.hybrid_search(query, top_k=top_k)
        
        # 2. QASystemìœ¼ë¡œ ë‹µë³€ ìƒì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
        qa_system = st.session_state.qa_system
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = qa_system.build_context(search_results, max_chunks=top_k)
        
        # LLM ë‹µë³€ ìƒì„± (use_history íŒŒë¼ë¯¸í„°ë¡œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì œì–´)
        answer = qa_system.generate_answer(
            query, 
            context, 
            temperature=temperature,
            use_history=use_conversation
        )
        
        if not answer:
            return "ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", []
        
        # 3. ì°¸ê³  ë¬¸ì„œ ì •ë¦¬
        references = []
        for i, result in enumerate(search_results[:top_k], 1):
            metadata = result.get("metadata", {})
            content = result.get("content", "")
            
            # ê¸°ê´€ ì •ë³´
            institution = metadata.get("institution", "unknown")
            institution_map = {
                "hd": "HD í˜„ëŒ€",
                "kb": "KBê¸ˆìœµ",
                "khi": "KHI ì£¼íƒê¸ˆìœµ"
            }
            source_name = institution_map.get(institution, institution)
            
            # ë¬¸ì„œ íƒ€ì…
            doc_type_map = {
                "text": "ë³¸ë¬¸",
                "table": "í‘œ",
                "image": "ê·¸ë˜í”„"
            }
            doc_type = doc_type_map.get(metadata.get("doc_type"), "ë³¸ë¬¸")
            
            references.append({
                "page": metadata.get("page", "N/A"),
                "text": content[:300],  # ì²« 300ìë§Œ
                "source": f"{source_name} - {doc_type}",
                "institution": source_name
            })
        
        return answer, references
        
    except Exception as e:
        print(f"Error in generate_response: {e}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", []

# ë©”ì¸ ì˜ì—­ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([2, 1])

with col1:
    st.title("ğŸ’¬ ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸ë´‡")
    
    # ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€
    if len(st.session_state.messages) == 0:
        st.markdown("""
        <div class="bot-message">
            <strong>ğŸ›ï¸ ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸ë´‡</strong><br><br>
            ì•ˆë…•í•˜ì„¸ìš”! ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸ë´‡ì…ë‹ˆë‹¤. ì§€ì—­(ì˜ˆ: ì„œìš¸ ê°•ë‚¨êµ¬), ê±°ë˜ì¢…ë¥˜
            (ë§¤ë§¤/ì „ì„¸), ê¸°ê°„(ì˜ˆ: ìµœê·¼ 3ê°œì›”) ë“±ì„ ì…ë ¥í•˜ì‹œë©´ ìµœì‹  ë™í–¥ ìš”ì•½ì„ ì œ
            ê³µí•©ë‹ˆë‹¤.
        </div>
        """, unsafe_allow_html=True)
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.markdown(f'<div class="user-message">{message["content"]}</div>', 
                       unsafe_allow_html=True)
        else:
            st.markdown(f'<div class="bot-message"><strong>ğŸ›ï¸ ë¶€ë™ì‚° ì¸ì‚¬ì´íŠ¸ë´‡</strong><br><br>{message["content"]}</div>', 
                       unsafe_allow_html=True)
            
            # ì°¸ê³ ìë£Œ í‘œì‹œ (ì ‘ì„ ìˆ˜ ìˆëŠ” í˜•íƒœ)
            if "references" in message and message["references"]:
                with st.expander("ğŸ” ê·¼ê±° ìë£Œ ë° ë°ì´í„° í™•ì¸"):
                    for ref in message["references"]:
                        st.markdown(f"""
                        <div class="reference-box">
                            <strong>REFERENCE TEXT (PAGE {ref['page']})</strong><br>
                            <small>ì¶œì²˜: {ref.get('source', 'N/A')}</small><br><br>
                            "{ref['text']}"
                        </div>
                        """, unsafe_allow_html=True)
    
    # ìµœê·¼ ì§ˆë¬¸ ë²„íŠ¼ì„ í´ë¦­í•œ ê²½ìš° ì²˜ë¦¬
    if 'selected_question' in st.session_state:
        user_input = st.session_state.selected_question
        del st.session_state.selected_question
    else:
        # ì±„íŒ… ì…ë ¥
        user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ) 2024ë…„ 1ë¶„ê¸° ì„œìš¸ ì§€ì—­ë³„ ì£¼íƒ ê°€ê²© ë³€ë™ë¥ ì€?")
    
    if user_input:
        # ì‚¬ìš©ì ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.user_questions.append(user_input)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "user",
            "content": user_input
        })
        
        # AI ì‘ë‹µ ìƒì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
        bot_response, references = generate_response(
            user_input, 
            temperature, 
            top_k,
            use_conversation
        )
        
        st.session_state.messages.append({
            "role": "assistant",
            "content": bot_response,
            "references": references
        })
        
        st.rerun()

with col2:
    st.markdown("### ì‹œê°í™” ë¯¸ë¦¬ë³´ê¸°")
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š í‘œ ë³´ê¸°", "ğŸ“ˆ ì°¨íŠ¸ ë³´ê¸°", "ğŸ”¤ JSON ë³´ê¸°"])
    
    with tab1:
        st.info("ì‹œê°í™” ì˜ì—­ (ì°¨íŠ¸ / í‘œ)")
    
    with tab2:
        st.info("ì°¨íŠ¸ ë³´ê¸°")
    
    with tab3:
        st.info("JSON ë³´ê¸°")
    
    st.markdown("---")
    st.markdown("### ì¶œì²˜ / ë ˆí¼ëŸ°ìŠ¤")
    st.caption("ê²€ìƒ‰ ê²°ê³¼ì—ì„œ êµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸ì™€ ì¶œì²˜ ë¦¬ìŠ¤íŠ¸")
    
    # ìµœì‹  ë©”ì‹œì§€ì˜ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ í‘œì‹œ
    if st.session_state.messages:
        last_messages = [msg for msg in st.session_state.messages if msg["role"] == "assistant"]
        if last_messages and "references" in last_messages[-1]:
            references = last_messages[-1]["references"]
            if references:
                for idx, ref in enumerate(references, 1):
                    source = ref.get("source", "N/A")
                    page = ref.get("page", "N/A")
                    st.markdown(f"**[{idx}]** {source} ({page}í˜ì´ì§€)")
            else:
                st.caption("ì•„ì§ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.caption("ì•„ì§ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.caption("ì•„ì§ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    pass